{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Key to Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "TEST_SIZE = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"brian_keylogs_clean.csv\")\n",
    "el = pd.read_csv(\"eleanor_keylogs_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize_that_bish(df, top_pairs=None):\n",
    "    data = pd.DataFrame(df.groupby(\"pair\")['delta'].median().reset_index())\n",
    "    if top_pairs:\n",
    "        data = data.where(data[\"pair\"].isin(top_pairs)).dropna()\n",
    "    data.columns = [\"pair\", \"delta_avg\"]\n",
    "    data = data.reset_index()\n",
    "    del data[\"index\"]\n",
    "    data = data.sort_values(\"pair\", ascending=False)\n",
    "    return data.transpose()\n",
    "\n",
    "def split_data(data, test_size = 0.33, top_pairs=None):\n",
    "    data = shuffle(data)\n",
    "    train, test = train_test_split(data, test_size=test_size)\n",
    "    return featurize_that_bish(train, top_pairs), featurize_that_bish(test, top_pairs)\n",
    "\n",
    "def combine_data(a, b):\n",
    "    new = pd.DataFrame(a)\n",
    "    new.append(b, axis=1)\n",
    "    return new\n",
    "\n",
    "def create_regression_parameters(train_list, test_list, labels):\n",
    "    y = labels #np.array(list(range(len(train_list))))\n",
    "    train = train_list[0]\n",
    "    test = test_list[0]\n",
    "    for i in range(1, len(train_list)):\n",
    "        train = train.append(train_list[i])\n",
    "        test = test.append(test_list[i])\n",
    "    return np.asmatrix(train), np.asmatrix(test), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Key.space,'f'\", \"'e','a'\", \"'o','f'\", \"'n','e'\", \"'h',Key.space\", \"'l','a'\", \"'s','e'\", \"'d','d'\", \"'l',Key.space\", \"'e','n'\", \"'c','t'\", \"'e','s'\", 'Key.space,Key.backspace', \"'.',Key.space\", \"'o','r'\", \"'l','i'\", \"Key.space,'s'\", \"'t','o'\", \"Key.shift,'('\", \"'c','h'\", \"'n','t'\", \"'p','r'\", \"Key.space,'h'\", \"Key.space,'o'\", \"'v','e'\", 'Key.left,Key.left', 'Key.right,Key.right', \"'y',Key.space\", \"'c','a'\", \"'e','t'\", \"'i','o'\", \"'e','r'\", \"'a','t'\", \"'n','d'\", \"'c','o'\", \"Key.space,'m'\", \"'g',Key.space\", \"'h','i'\", \"Key.space,'r'\", \"'h','e'\", \"'r','a'\", 'Key.backspace,Key.shift', \"Key.space,'d'\", \"'m','e'\", \"'e','c'\", \"'a','l'\", \"'e','d'\", \"'t','i'\", \"Key.space,'t'\", \"'d','e'\", \"'o','u'\", \"'r','e'\", \"'r','o'\", \"'m','a'\", \"'r',Key.space\", \"'n','g'\", \"'i','t'\", \"Key.space,'b'\", \"'s',Key.space\", \"'e','e'\", \"Key.space,'i'\", \"'f',Key.space\", \"'d',Key.space\", \"'t',Key.space\", \"'o','n'\", \"'a','s'\", \"Key.space,'l'\", \"'l','l'\", \"Key.space,'w'\", \"'d','i'\", \"'l','e'\", \"Key.space,'c'\", \"'s',Key.enter\", \"'e','l'\", \"'t','a'\", \"'t','h'\", \"'a','r'\", \"'u','t'\", \"'a','n'\", \"'t','e'\", \"'p','e'\", \"'i','s'\", \"'e',Key.space\", 'Key.backspace,Key.backspace', \"'o',Key.space\", \"'h','a'\", \"Key.space,'e'\", \"'a',Key.space\", \"'k','e'\", \"'c','e'\", \"'i','n'\", \"'o','m'\", \"Key.space,'a'\", \"'b','e'\", \"'s','t'\", \"'a','c'\", \"'r','i'\", \"'n',Key.space\", 'Key.space,Key.shift', \"Key.space,'p'\"}\n"
     ]
    }
   ],
   "source": [
    "top_pairs = set([\"'t','h'\", \"'a','r'\", \"'h','e'\", \"'t','e'\", \"'a','n'\", \"'s','e'\", \"'i','n'\", \"'m','e'\", \"'e','r'\", \"'s','a'\", \"'n','d'\", \"'n','e'\", \"'r','e'\", \"'w','a'\", \"'e','d'\", \"'v','e'\", \"'e','s'\", \"'l','e'\", \"'o','u'\", \"'n','o'\", \"'t','o'\", \"'t','a'\", \"'h','a'\", \"'a','l'\", \"'e','n'\", \"'d','e'\", \"'e','a'\", \"'o','t'\", \"'s','t'\", \"'s','o'\", \"'n','t'\", \"'d','t'\", \"'o','n'\", \"'l','l'\", \"'a','t'\", \"'t','t'\", \"'h','i'\", \"'e','l'\", \"'a','s'\", \"'r','o'\", \"'i','t'\", \"'a','d'\", \"'n','g'\", \"'d','i'\", \"'i','s'\", \"'e','w'\", \"'o','r'\", \"'r','a'\", \"'e','t'\", \"'r','i'\", \"'o','f'\", \"'s','h'\", \"'t','i'\" ])\n",
    "print(top_pairs)\n",
    "bf_train, bf_test = split_data(df, TEST_SIZE, top_pairs=top_pairs)\n",
    "el_train, el_test = split_data(el, TEST_SIZE, top_pairs=top_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 99        98        97        96        95        94  \\\n",
      "delta_avg  0.682778  0.571518  0.130982  0.127899  0.124174  0.154627   \n",
      "\n",
      "                 93        92        91        90    ...           9   \\\n",
      "delta_avg  0.201946  0.139849  0.164586  0.171888    ...     0.096216   \n",
      "\n",
      "                  8         7        6         5         4         3   \\\n",
      "delta_avg  0.0916786  0.114861  0.14311  0.136896  0.134102  0.083998   \n",
      "\n",
      "                 2         1         0   \n",
      "delta_avg  0.105743  0.171842  0.270184  \n",
      "\n",
      "[1 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "labels = [\"El\", \"Brian\"]\n",
    "train_list = [el_train.iloc[1:], bf_train.iloc[1:]]\n",
    "test_list = [el_test.iloc[1:], bf_test.iloc[1:]]\n",
    "train, test, y = create_regression_parameters(train_list, test_list, labels)\n",
    "\n",
    "print(train_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49408496,  0.50591504]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict_proba(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
